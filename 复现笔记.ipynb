{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c7ca0df",
   "metadata": {},
   "source": [
    "<img src=\"readme.png\" alt=\"Schematic diagram of DigNet generation network\" />\n",
    "\n",
    "## 1.输入数据\n",
    "### 1.1 \n",
    "基因表达谱和GRN(数据格式见`Supplement S1`)\n",
    "\n",
    "- **'net' variable**: Contains the adjacency matrix of network data, a 0-1 weight matrix (Numpy ndarray). Non-0-1 values can also be loaded, sized cell * cell.\n",
    "- **'exp' variable**: Contains experimental data in DataFrame format, preprocessed scRNA-seq results (CSV format), sized gene * cell.\n",
    "\n",
    "\n",
    "### 1.2\n",
    "只输入基因表达谱, 有方法构建一个参考网络(见manuscript, 即readme文档使用的输入格式), 接下来都是使用该格式输入\n",
    "\n",
    "预处理:参考`CancerDatasets/Create_BRCA_data.py`,基因表达谱是一个csv或xlsx文件,第一行是cell numbers, 第一列是gene symbol IDs\n",
    "\n",
    "\n",
    "\n",
    "## 2.文件和文件夹\n",
    "\n",
    "- `pre_train/`: The pre-trained DigNet model provided in this article\n",
    "- `Cancer_datasets/`: Contains preprocessed results of the E-MTAB-8107 data used in the manuscript\n",
    ">预处理后的数据,但是在pathway/中使用的是预处理前的数据.预处理前应该是csv格式,预处理后应该是mat,data格式.根据解压出的是csv,判断该文件夹下其实是预处理前的数据\n",
    "\n",
    "- `pathway/`: sub-function file containing data preprocessing\n",
    "\n",
    "> 预处理\n",
    "> MaxMinNormalization(x, Min=0, Max=1): 归一化到(0,1)区间\n",
    "\n",
    "> cal_percent(new_bit_crop,corr_TF_Gene, MI_TF_Gene,net_bit_orig):<br>\n",
    "1.首先new_bit_origC赋值为net_bit_orig和的new_bit_crop交集,然后计算在new_bit_crop中的比例,记为NUM_ORIG<br>\n",
    "2.corr_TF_GeneC赋值为corr_TF_GeneC和new_bit_crop的交集,然后计算与net_bit_origC不相交的个数在new_bit_crop中的比例,记为NUM_PCC<br>\n",
    "3.对MI_TF_Gene的操作与corr_TF_GeneC相同,得到NUM_MI<br>\n",
    "4.如果NUM_ORIG,NUM_PCC,NUM_MI相加不是100,则缩放使得和为100<br>\n",
    "5.NUM_PCC+NUM_MIover>50 -> overflow = True<br>\n",
    "else: overflow = False<br>\n",
    "return NUM_ORIG, NUM_PCC, NUM_MI, overflow\n",
    "\n",
    ">load_sergio_count(filename='pathway/simulation/SERGIO_data_node_2000.data',  num=None, logp=True):<br>\n",
    "用pickle加载filename,如果有num,则选择索引为num的数据,如果logp == True, 则进行log1p变换<br>\n",
    "return batch\n",
    "\n",
    ">plot_GRN_percent(network_percent):<br>\n",
    "画一个\"Train_GRN_pecent_bar.pdf\"柱形图,<br>\n",
    "以pathway为横坐标,<br>\n",
    "NUM_ORIG,NUM_PCC,NUM_MI为纵坐标\n",
    "\n",
    ">compute_mutual_information(df):<br>\n",
    "df每行是一个特征<br>\n",
    "计算df特征间的的mi(互信息)<br>\n",
    "return mi_matrix\n",
    "\n",
    ">compare_char(charlist, setlist):<br>\n",
    "index为setlist中charlist的索引<br>\n",
    "一般来说index方法只能在list中找一个值的索引,所以charlist可能不是list类型,只是一个值<br>\n",
    "return index\n",
    "\n",
    ">calRegnetwork(human_network, GRN_GENE_symbol):<br>\n",
    "human_network_TF_symbol = human_network第0列<br>\n",
    "human_network_Gene_symbol= human_network第2列<br>\n",
    "GRN_GENE_symbol中找调控基因(TF)和靶基因(Gene)<br>\n",
    "这一段循环方式低效,应该可以改进<br>\n",
    "return pd.DataFrame(network, columns=['TF', 'Gene'])\n",
    "\n",
    ">load_KEGG(kegg_file='pathway/kegg/KEGG_all_pathway.pkl'):<br>\n",
    "如果 pkl 文件存在，则加载它,如果 pkl 文件不存在，则运行 KEGG.py 文件\n",
    "\n",
    ">high_MI(exp_pca_discretized, exp_pca, net_bit, parm):<br>\n",
    "计算exp_pca_discretized的互信息,保存在row_MI中,将row_MI的对角线设置为0.然后筛选大于阈值的调控基因和靶基因,把调控基因和靶基因保存到MI_TF_Gene中,并且与net_bit拼接去重.<br>\n",
    "return net_bit, MI_TF_Gene\n",
    "\n",
    ">high_pearson(exp_pca, net_bit, parm):<br>\n",
    "与high_MI中的操作类似,不过未经过离散化.<br>\n",
    "值得注意的是,mi和pearson相关系数都是对称的,也就是说调控基因和靶基因(有向边)并没有明确的区分?\n",
    "\n",
    ">from_cancer_create(BRCA_exp_filter_saver, KEGG, parm, lim=200, test_pathway=None, Other_Pathway=None, human_network=None):<br>\n",
    "1.获得exp表达谱<br>\n",
    "2.对exp进行标准化<br>\n",
    "3.net_bit,用calRegnetwork函数在human_network的先验信息中得到,由两列组成:调控基因TF和靶基因Gene<br>\n",
    "4.net_bit_orig:net_bit的拷贝<br>\n",
    "5.exp_pca:通过pca降维,列数比exp少一<br>\n",
    "6.将exp_pca分成256个离散化的区间(0-255),保存为exp_pca_discretized<br>\n",
    "7.用上面两个函数计算高pearson和MI的调控-靶基因,添加到net_bit<br>\n",
    "8.创建邻接矩阵adj_matrix<br>\n",
    "8.1 矩阵形状:基因个数(exp.index) * 基因个数<br>\n",
    "8.2 有调控关系的(TF-Gene)在矩阵中置1<br>\n",
    "8.3 经过cal_del_TF_edge(exp.index)函数,将exp分成TF,GENE两个不相交的部分<br>\n",
    "然后在邻接矩阵adj_matrix中将下标为GENE,TF的点置0(这样就从无向图变成了有向图)<br>\n",
    "9.predicted_adj_matrix, new_graph = pca_cmi(exp_pca_discretized, net_bit, parm['pmi_percent'], 1):<br>\n",
    "参考**其他文件**,通过删除cmi较小的边,获得邻接矩阵和图.此处有重要的问题,即离散化的数据用多元正态分布的方法计算cmi不合理.<br>\n",
    "new_bit_crop是更新后的图的所有边<br>\n",
    "10.以上有两个邻接矩阵adj_matrix,predicted_adj_matrix.前者是基于先验知识(查表)删除回路边,后者是用cmi删除cmi小的边,以下要对两者进行比较<br>\n",
    "11.分为三种情况,选择边最少的邻接矩阵<br>\n",
    "11.1 predicted_adj_matrix所有值为0<br>\n",
    "11.2 (np.sum(adj_matrix) / np.sum(predicted_adj_matrix)) < 0.5:<br>\n",
    "return exp, adj_matrix, new_row<br>\n",
    "11.3 else:<br>\n",
    "return exp, predicted_adj_matrix, new_row<br>\n",
    "评价:这里用0.5比较,可能是因为adj_matrix是有向图<br>\n",
    "如果predicted_adj_matrix还是一个对称的无向图,与有向的adj_matrix的边数相同,predicted_adj_matrix会多一倍的边.<br>\n",
    "但是如果选了predicted_adj_matrix,为什么不把他从对称矩阵(无向)变成有向图?<br>\n",
    "而且经过复现并不是对称图,这个判断几乎只会选到predicted_adj_matrix,后续可以尝试改成与1比较.\n",
    "\n",
    ">matrix2Data(adj_matrix, node_feature, num=0, adj2data=True, log_trans=True, metacell=False, Cnum=100, k=20):<br>\n",
    "1.1如果node_feature是list<br>\n",
    "node_feature中选择第num个,转换为tensor,得到x<br>\n",
    "1.2如果node_feature不是list<br>\n",
    "直接将node_feature转换为tensor,得到x<br>\n",
    "log_trans默认True,进行对数变换x = log(1+x)<br>\n",
    "2.归一化:使用MinMaxScalar,得到x_normalized<br>\n",
    "3.1如果adj2data是True(默认为True),此时邻接矩阵是0-1编码的,即表示无权图<br>\n",
    "adj_matrix转换为tensor<br>\n",
    "indices_tensor是所有的边,每一列代表一条边的头节点和尾节点<br>\n",
    "num_edges是边的数量<br>\n",
    "values_tensor是一个全为1的张量,长度是边的数量<br>\n",
    "3.2如果adj2data是False,此时邻接矩阵是一个稠密的,图中每个点(i,j)都有权重的数组<br>\n",
    "indeces = 邻接矩阵的所有索引,每一列代表一条边的头节点和尾节点<br>\n",
    "values = 邻接矩阵的所有值<br>\n",
    "然后转换成张量,indeces_tensor,values_tensor<br>\n",
    "4.创建data,一个图,节点特征为x_normalized(形状为(节点数,特征数)),边的索引和权重分别是indeces_tensor,values_tensor,索引为0-(节点数-1)<br>\n",
    "return data\n",
    "\n",
    ">load_pathway_mat(file_path, num=0):<br>\n",
    "从mat类型数据中读取data<br>\n",
    "node_feature是8个节点的特征,这个8是怎么确定的?<br>\n",
    "adj_matrix是data中的邻接矩阵<br>\n",
    "Data1 = matrix2Data(adj_matrix, node_feature, num=num)创建图<br>\n",
    "return Data1\n",
    "\n",
    ">create_batch_dataset_from_mat(matnum=100, test=False):<br>\n",
    "1.如果test = True:测试集<br>\n",
    "直接加载第matnum个mat文件到batch<br>\n",
    "2.否则:训练集<br>\n",
    "加载序号为1-matnum的所有mat文件到batch<br>\n",
    "return batch\n",
    "\n",
    ">create_batch_dataset_simu(filename='./pathway/simulation/SERGIO_data_node_2000.data', num=None, device=None,test=False,adddata=None, metacell=True, Cnum=100, k=20):<br>\n",
    "1.如果test == True 测试集<br>\n",
    "直接加载文件,文件中有邻接矩阵net,基因谱exp,保存到batch<br>\n",
    "return batch<br>\n",
    "2.如果test == False 训练集<br>\n",
    "2.1 文件中有多个net,exp,遍历地取出保存到data_list(相当于一个batch), edge_percent(计算边在图中的比例)<br>\n",
    "2.2 edge_percent = 所有edge_percent的平均值<br>\n",
    "2.3 如果有adddata(默认没有), 则在data_list,edge_percent中加入新的数据<br>\n",
    "2.4 创建batch<br>\n",
    "2.5 return batch,edge_persent\n",
    "\n",
    ">cal_metacell(BRCA_exp_filter_saver, Cnum=100, k=20):<br>\n",
    "BRCA_exp_filter_savert,形状(样本个数, 特征数),具体来说是(细胞个数,基因个数)<br>\n",
    "K_list,k近邻得到每个细胞的k个邻居,形状(细胞个数,k)<br>\n",
    "ALL_C_list,长度为细胞个数的数组,元素是基因序号(0-基因个数)<br>\n",
    "S,元素为None,长度为Cnum的list,用于存储细胞索引<br>\n",
    "old_S,S的拷贝<br>\n",
    "Nc_max_list,(1,Cnum)的0数组,用于存储S中对应细胞的最大k近邻<br>\n",
    "1.while循环:<br>\n",
    "1.1 ALL_C_list_current,不在S中的基因索引,即一开始是所有的细胞<br>\n",
    "1.2 对ALL_C_list_current中的c循环,c不在S中<br>\n",
    "1.2.1 Nc_max,对一个细胞c,所有S中的细胞与他k近邻并集最多的个数<br>\n",
    "1.2.2 a.如果Nc_max > Nc_max_list中的最小值(初始是0),则对于最小值的位置,S置c,Nc_max_list置Nc_max.其实这个所谓最小值的位置,就是从0递增.<br>\n",
    "b.elif Nc_max是k*2,即S中存在一个与c的k近邻不交的细胞<br>\n",
    "对于S中最大值的位置,S置c,Nc_max_list置Nc_max<br>\n",
    "1.2.3 如果一段时间S没有更新,则结束while<br>\n",
    "1.3 进行Cnum(即metacell的数量)次循环,每次序号为cn<br>\n",
    "1.3.1 对于S在cn位置的c细胞,Nc_max是所有S中的细胞与他k近邻并集最多的个数<br>\n",
    "1.3.2 如果Nc_max>原来位置的值则更新S和Nc_max_list<br>\n",
    "评价:1.3的循环意义不明,S和Nc_max_list已经在1.2更新过了,这一段似乎完全没用<br>\n",
    "2.对S进行排序,确认不含None,不含重复值<br>\n",
    "3.定义BRCA_exp_filter_saver为dataframe<br>\n",
    "4.对于S中的每个细胞si, 在K_list中取这个细胞的前x个相邻细胞,x为一个metacell中细胞个数,这些细胞每个基因的平均值作为metacell中的基因的值,然后保存到BRCA_exp_filter_saver中,列名为'c' + str(si)<br>\n",
    "评价:x的计算方式:所有细胞数除metacell个数, 即一个metacell中的细胞数<br>\n",
    "既然要取最近的x个点,为什么k近邻中近邻数量是20,而不是直接用x(细胞总数/100)<br>\n",
    "这是为了利用切片的性质,即使x大于20也可以取20个细胞作为一个metacell,不会报错<br>\n",
    "5.最终得到的BRCA_exp_filter_saver形状为(基因个数,Cnum)<br>\n",
    "6.return BRCA_exp_filter_saver\n",
    "\n",
    ">create_batch_dataset_from_cancer(filepath='CancerDatasets/DCA/BRCA_output.csv',test_pathway='hsa05224', test=False, device=None, metacell=True, Cnum=100, k=20, lim=200, return_list=False):<br>\n",
    "1.1 metacell == True 需要metacell处理<br>\n",
    "filepath中读取BRCA_exp_filter_saver,数据处理有误,多删了一列<br>\n",
    "用函数cal_metacell重新获得BRCA_exp_filter_saver,(基因个数,Cnum= metacell个数)<br>\n",
    "1.2 metacell == False 不需要metacell处理<br>\n",
    "从filepath中读取BRCA_exp_filter_saver,(基因个数,细胞个数)<br>\n",
    "2.读取KEGG<br>\n",
    "3.Regnetwork_path = 'pathway/Regnetwork/2022.human.source'<br>\n",
    "这是写死在函数里,不是传递的参数<br>\n",
    "从这个路径获得human_network<br>\n",
    "4.network_percent是一个DataFrame,<br>\n",
    "列名为Pathway,NUM_ORIG,NUM_PCC,NUM_MI<br>\n",
    "5.1 如果test == True,测试集<br>\n",
    "通过from_cancer_create,matrix2Data两个函数获得batch<br>\n",
    "return batch<br>\n",
    "5.2 如果test == False,训练集<br>\n",
    "pathway_ID_list是KEGG的键<br>\n",
    "5.2.1 遍历pathway_ID_list中的Other_Pathway<br>\n",
    "network_percent保存每条边的出节点和入节点<br>\n",
    "data_list保存每个Data,即图<br>\n",
    "edge_percent保存每个图中边占图的大小的比例,即稀疏程度<br>\n",
    "5.2.2 return_list(默认为False)控制返回的data_list是list类型还是转换为tensor类型的batch.<br>\n",
    "默认返回tensor类型的batch还有edge_percent取平均值<br>\n",
    "return batch, edge_percent\n",
    "\n",
    ">复现<br>\n",
    "先验信息的来源:KEGG,Regnetwork<br>\n",
    "discrete文件夹下添加__init__.py文件,才能将该文件夹识别为模块,运行当前文件\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433b8264",
   "metadata": {},
   "source": [
    "\n",
    "- `pathway/simulation/`: synthetic network and gene expression profile generated by SERGIO\n",
    "- `discrete/`: model-related configuration files\n",
    "在接下来的model中调用了该文件下的两个文件,剩余两个未被调用,暂时不看\n",
    "### 2.1 discrete/network_preprocess.py\n",
    ">class PlaceHolder:<br>\n",
    "1.def __init__(self, X, E, y):<br>\n",
    "初始化<br>\n",
    "2.def type_as(self, x: torch.Tensor):<br>\n",
    "将X,E,y的类型修改为和x相同,即张量<br>\n",
    "3.def mask(self, node_mask, collapse=False):<br>\n",
    "node_mask:(bs,n)<br>\n",
    "x_mask,e_mask1,e_mask2,都是在node_mask的基础上拓展维度,维度分别是:\n",
    "(bs,n,1),(bs,n,1,1),(bs,1,n,1)<br>\n",
    "3.1 如果collapse == True:<br>\n",
    "更新E的形状为(bs, n, n)然后根据mask把含0的(被屏蔽)节点置-1<br>\n",
    "3.2 如果collapse == False:<br>\n",
    "更新X,把mask中0的点置0<br>\n",
    "更新E,把mask中0的点置0<br>\n",
    "return self\n",
    "\n",
    ">def to_dense(x, edge_index, edge_attr, batch=None, training=True, max_num_nodes=None):<br>\n",
    "x:(num_nodes, node_attr)<br>\n",
    "batch:(num_nodes),用于指示x中的每一行(即每个节点)属于哪一个batch<br>\n",
    "1.处理节点<br>\n",
    "1.1 if training:<br>\n",
    "X:(bs, max_num_nodes, node_attr)经过密集处理的批次张量<br>\n",
    "node_mask:(bs, max_num_nodes)为0的节点指示为掩码,因为每个batch可能节点数量不同<br>\n",
    "1.2 else:<br>\n",
    "X = x<br>\n",
    "node_mask = None<br>\n",
    "2.处理边<br>\n",
    "E: (bs, max_num_nodes, max_num_nodes),源代码中每条边的特征为常数,即权重.如果边的特征是向量,则形状为(bs, max_num_nodes, max_num_nodes,edge_attr)<br>\n",
    "E_onehot:(s, max_num_nodes, max_num_nodes,2)独热编码,即最后一个维度是[1,0],(对应权重为0)或者[0,1],(对应权重为1)<br>\n",
    "return PlaceHolder(X=X, E=E_onehot, y=None), node_mask,max_num_nodes\n",
    "\n",
    ">def get_max_node(data):<br>\n",
    "获得最大节点数,似乎把data是PlaceHolder类型的,还把X写成小写,而且其他地方没有用到,忽略\n",
    "\n",
    ">def encode_no_edge(E):<br>\n",
    "E:(bs, n, n, 2)<br>\n",
    "然后写了个冗余的判断,跳过<br>\n",
    "no_edge:(bs,n,n),bool类型,E中最后一个维度的和为0就置1<br>\n",
    "first_elt:(bs,n,n),E的最后一个维度的第1维<br>\n",
    "将这个first_elt中no_edge的位置置1,相当于没有边,再赋值给E的最后一个维度的第1维,即在矩阵中编码为[0,1]<br>\n",
    "这又是一个错误,没有边应该编码为[1,0],应该在first_elt时取第0维而不是第1维<br>\n",
    "diag:(bs,n,n)bool类型的对角阵<br>\n",
    "然后用diag将E的对角线元素置0<br>\n",
    "return E\n",
    "\n",
    ">def unnormalize(X, E, y, norm_values, norm_biases, node_mask, collapse=False):<br>\n",
    "对X,E,y进行反归一化,即乘标准差后加均值\n",
    "return PlaceHolder(X=X, E=E, y=y).mask(node_mask, collapse)\n",
    "\n",
    ">def normalize(X, E, y, norm_values, norm_biases, node_mask):<br>\n",
    "对E,y归一化<br>\n",
    "diag:(E.shape[0], E.shape[1], E.shape[1]),其中第1,2维的数组是对角线矩阵,类型为bool<br>\n",
    "将E在diag为True的对应位置(对角线)置0<br>\n",
    "return PlaceHolder(X=X, E=E, y=y).mask(node_mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684681ab",
   "metadata": {},
   "source": [
    "\n",
    "### 2.2 discrete/diffusion_utils.py\n",
    ">class CrossEntropyMetric(Metric):\n",
    "与discrete/models/train_metrics.py中同名的类相同,用于计算交叉熵\n",
    "\n",
    ">class SumExceptBatchMetric(Metric):\n",
    "总和值/样本数,用于算出一个平均值\n",
    "\n",
    ">class SumExceptBatchKL(Metric):\n",
    "用于计算p,q的kl散度的平均值\n",
    "\n",
    ">class NLL(Metric):\n",
    "用于计算batch_nll的平均值\n",
    "\n",
    ">def linear_beta_schedule(timesteps):\n",
    "用于生成 DDPM（Denoising Diffusion Probabilistic Models）中的线性噪声调度（beta schedule）。噪声调度控制着在扩散过程中如何逐步向数据添加噪声，以及在逆过程中如何逐步去噪。\n",
    "返回一个长度为timesteps的等差数列\n",
    "\n",
    ">def cosine_beta_schedule_discrete(timesteps, s=0.008):\n",
    "生成余弦噪声调度，通过余弦函数平滑控制噪声强度\n",
    "返回长度为timesteps+1的噪声,随着时间步增加噪声逐渐增大\n",
    "\n",
    ">def get_diffusion_betas(spec):\n",
    "得到噪声beta,既然有这个函数,上面两个函数基本就没用了\n",
    "spec:dict,其中可以指定噪声类型,有三种类型:linear,cosine,jsd\n",
    "jsd实际上是倒数调度,即1/T,1/(T-1),...1,这与jsd不同.以及他提供的论文DPM使用的二项式扩散过程的调度不同\n",
    "\n",
    ">def custom_beta_schedule_discreteDig(timesteps, average_num_nodes=50, s=0.008):\n",
    "与余弦调度重复,跳过\n",
    "\n",
    ">def sample_discrete_max(X, probE, node_mask, test=False):\n",
    "X: bs, n, dx_out\n",
    "probE: bs, n, n, de_out\n",
    "node_mask: bs, n\n",
    "inverse_edge_mask: bs, n, n,根据node_mask获得途中要屏蔽的边并取反, 结果上True表示要屏蔽,False表示不屏蔽\n",
    "diag_mask:bs, n, n,对角线为1的矩阵\n",
    "probE的对角线以及要屏蔽的位置,都置为1/ de_out\n",
    "E_t:(bs, n, n) 元素为probE最后一个维度取最大值的索引,然后把对角线置1\n",
    "return PlaceHolder(X=X, E=E_t, y=None)\n",
    "\n",
    ">def sample_discrete_features(X, probE, node_mask, randomseed=42, test=True):\n",
    "X: bs, n, dx_out\n",
    "probE: bs, n, n, de_out\n",
    "node_mask: bs, n\n",
    "inverse_edge_mask: bs, n, n,根据node_mask获得途中要屏蔽的边并取反, 结果上True表示要屏蔽,False表示不屏蔽\n",
    "diag_mask:bs, n, n,对角线为1的矩阵\n",
    "probE的对角线以及要屏蔽的位置,都置为1/ de_out\n",
    "probE形状改为(bs*n*n,de_out),最后一个维度即为抽样概率\n",
    "抽样后复原形状得到E_t:(bs,n,n),对角线置1\n",
    "return PlaceHolder(X=X, E=E_t, y=None)\n",
    "\n",
    ">def Evaluation(y_true, y_pred, flag=False):\n",
    "y_p,从y_pred转化而来的np数组(n,)\n",
    "y_t,从y_true转化而来的np数组(n,)\n",
    "用y_t,y_p计算AUC\n",
    "用y_t,y_p计算roc曲线,包括:fpr, tpr, thresholds\n",
    "best_threshold = thresholds中令tpr - fpr最大的值\n",
    "用y_t,y_p计算PR曲线,包括:precision,recall,thresholds\n",
    "AUPR = PR曲线下面积\n",
    "AUPR_norm = AUPR / y_t均值(正样本比例)\n",
    "y_p对于大于best_thresholds的部分置1,其余部分置0,从概率分布变成0-1\n",
    "用y_t, y_p计算f1\n",
    "return {'AUC': AUC, 'AUPR': AUPR, 'AUPR_norm': AUPR_norm, 'F1': f1}\n",
    "\n",
    ">def compute_batched_over0_posterior_distribution(X_t, Qt, Qsb, Qtb):\n",
    "对边计算后验分布\n",
    "0,t都是时间步,已知x_t,计算x_0的后验分布的公式:\n",
    "$$\n",
    "\\text{posterior} = \\frac{(X_t \\cdot Q_t^T) \\odot (x_0 \\cdot Q_{sb})}{x_0 \\cdot Q_{tb} \\cdot X_t^T}\n",
    "$$\n",
    "out输出的形状:(bs, n*n, d0, d_t - 1)\n",
    "其中,n是边数,d0,d_t是0或者t时刻的特征维度\n",
    "\n",
    ">def sample_discrete_feature_noise(X, limit_dist, node_mask, seed=42):\n",
    "X:()\n",
    "node_mask:(bs, n_max)\n",
    "limit_dist:dist\n",
    "e_limit:(bs,n_max,n_max,de)边的分布概率\n",
    "U_E:(bs,n_max,n_max)每条边进行多元分布的采样结果,对角线置1\n",
    "long_mask:将node_mask改为long类型\n",
    "U_E修改为one-hot编码:(bs,n_max,n_max,de)\n",
    "y:(1,0)的空张量\n",
    "return PlaceHolder(X=X, E=U_E, y=y).mask(node_mask)\n",
    "\n",
    ">def delte_dig_from_batch(batchdata):\n",
    "将batchdata的对角线置1然后返回batachdata\n",
    "\n",
    ">def cal_del_TF_edge(GeneName):\n",
    "GeneName是一个包含了调控基因TF和靶基因Gene的list\n",
    "通过查表GRN/TF.txt,将这两者分开,得到他们在GeneName中的索引\n",
    "return GENE_ID_list, TF_ID_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7f79d7",
   "metadata": {},
   "source": [
    "- `discrete/models/`: Graph Transformer architecture\n",
    ">该目录下的graph_transformer.py使用dgl包.图神经网络常用的两个包pyg和dgl,本教程配置环境下载的是pyg,没有dgl,所以这个文件是无法直接运行的.<br>\n",
    "事实上,本文使用的模型都在transformer_model.py文件内,名字和用法不是很匹配.\n",
    "考虑到文档的长度和可读性, 对于该文件夹下所有可以运行的和模型有关的文件,在子标题下进行解读\n",
    "### 2.1 discrete/models/layers.py\n",
    ">class Xtoy(nn.Module):<br>\n",
    "处理节点特征,将平均值,最大值,最小值,标准差的信息结合起来然后通过一个线性层<br>\n",
    "输入X: (bs, n, dx)<br>\n",
    "输出out: (bs, dy)\n",
    "\n",
    ">class Etoy(nn.Module):<br>\n",
    "处理边的特征,将平均值,最大值,最小值,标准差的信息结合起来然后通过一个线性层<br>\n",
    "输入E: (bs, n, n, de)<br>\n",
    "输出out: (bs, dy)\n",
    "\n",
    ">def masked_softmax(x, mask, **kwargs):<br>\n",
    "掩码mask为0的部分忽略,但是这里似乎有误,如果mask全0,应该对整个张量都忽略(即返回全0张量), 但是原代码会返回原张量<br>\n",
    "掩码后经过一个softmax<br>\n",
    "返回的形状与x相同\n",
    "\n",
    "### 2.2 discrete/models/train_matrics.py\n",
    ">class CrossEntropyMetric(Metric):<br>\n",
    "Metric 是一个抽象基类,用于定义和计算各种评估指标.<br>\n",
    "preds和target:(bs * n, d) or (bs * n * n, d)<br>\n",
    "total_ce 累积交叉熵<br>\n",
    "total_samples 累积样本数量<br>\n",
    "输出: total_ce/total_samples\n",
    "\n",
    ">class NodeMSE(MeanSquaredError),class EdgeMSE(MeanSquaredError):<br>\n",
    "分别是点和边的MSE.MSE用于回归任务,但是对于边似乎是0-1的分类问题,需要进一步分析\n",
    "\n",
    ">class TrainLossDiscrete(nn.Module):<br>\n",
    "1.初始化<br>\n",
    "node_loss,edge_loss,y_loss均为交叉熵损失函数<br>\n",
    "lambda_train是传入参数<br>\n",
    "2.forward(self, masked_pred_E, nosoft_pred_E, true_E, CEloss=False):<br>\n",
    "前向传播过程<br>\n",
    "如果CEloss == True, masked_pred_E赋值为nosoft_pred_E\n",
    "输入--masked_pred_E,true_E:(bs, n, n, de)<br>\n",
    "reshape后--masked_pred_E,true_E:(bs * n * n, de)<br>\n",
    "mask_E:true_E最后一个维度存在不为0的则为True,全0则False,(bs * n * n)<br>\n",
    "masked_pred_E,true_E分别使用mask_E,删掉全为0的行,得到flat_pred_E,flat_true_E:(-1,de)<br>\n",
    "如果CEloss为True,计算flat_pred_E,flat_true_E的交叉熵,否则计算他们的二元交叉熵,得到loss_train<br>\n",
    "return loss_train<br>\n",
    "3.reset(self):<br>\n",
    "每次重置node_loss,edge_loss,y_loss<br>\n",
    "评价:实际计算损失函数用到的是torch库自带的交叉熵和二元交叉熵,node_loss,edge_loss,y_loss根本没有使用到,意义不明\n",
    "\n",
    ">def weights_init(m):<br>\n",
    "m是神经网络中的层,用xavier初始化attention层的权重,用kaiming初始化其他层(如线性层)的权重,bias初始化为0.关于两种方法见`5.2初始化与激活函数`\n",
    "\n",
    "### 2.3 discrete/models/trasformer_model.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb93338f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True, False, False, False,  True],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False,  True, False, False],\n",
       "         [False, False,  True, False, False]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "x = torch.randn(3,4,5) > 0.5\n",
    "mask = torch.zeros(size = (3,4,5))\n",
    "\n",
    "x[[True,False, False],:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3ad06f",
   "metadata": {},
   "source": [
    "\n",
    "- `denoising_diffusion_pytorch/`: Contains related sub-function files used for training/testing/initializing DigNet\n",
    "- `config.py`: Configure hyperparameters for training or testing DigNet\n",
    "- `DigNet.py`: Contains the process framework of DigNet\n",
    "- `Download_TF_file.py`: used to download TF list\n",
    "- `make_final_net.py`: Integrated voting sub-function\n",
    "- `Tutorial.py`: A quick tutorial for using DigNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb29d204",
   "metadata": {},
   "source": [
    "## 3.复现代码\n",
    "\n",
    "### 3.1 pathway/pathway.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54251eca",
   "metadata": {},
   "source": [
    "pathway/pathway.py中的主程序\n",
    "功能:创建data类型和mat类型的数据,保存在Cancer_datasets文件夹下\n",
    "有两种移除边的方式,1.基于先验知识(查表) 2.基于cmi\n",
    "增加输出判断采用了哪种方式, 发现所有文件都使用了cmi,但是有以下两个问题\n",
    "1. 计算cmi时,使用离散化而非连续化数据, 但是又假设是多元正态分布\n",
    "2. 删除边的两种方式得到的边数用0.5进行比较而不是1,这样选边较少的图几乎完全会选第二种cmi方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9789d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "from torch_geometric.data import Data, Batch\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.io as sio\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import random\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from discrete.diffusion_utils import cal_del_TF_edge\n",
    "from pathway.PCA_CMI import pca_cmi\n",
    "from pathway.pathway import *\n",
    "import powerlaw\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fe8dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "celllist = [\"T_cell\", \"B_cell\", \"Cancer\"]\n",
    "filelist = [33,39,42,53,60]\n",
    "# 此处根据修改Cancer_datasets中的文件修改,只做其中几个用于展示\n",
    "test_pathway = 'hsa05224'\n",
    "Cnum = 100\n",
    "k = 20\n",
    "KEGG = load_KEGG()\n",
    "# KEGG是dict,每一个key对应多个基因名\n",
    "Regnetwork_path = 'pathway/Regnetwork/2022.human.source'\n",
    "dtypes = {1: str, 3: str}\n",
    "# 第1,3列是数字,此处强行要求识别成字符串\n",
    "human_network = pd.read_csv(Regnetwork_path, sep='\\t', header=None, dtype=dtypes)\n",
    "# human_network是DataFrame,共4列,第0,2列分别是调控基因TF,靶基因Gene\n",
    "metacell = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1651ce03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALDOA</td>\n",
       "      <td>226</td>\n",
       "      <td>FBP1</td>\n",
       "      <td>2203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALDOB</td>\n",
       "      <td>229</td>\n",
       "      <td>FBP1</td>\n",
       "      <td>2203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALDOC</td>\n",
       "      <td>230</td>\n",
       "      <td>FBP1</td>\n",
       "      <td>2203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALDH2</td>\n",
       "      <td>217</td>\n",
       "      <td>ADH1A</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALDH1B1</td>\n",
       "      <td>219</td>\n",
       "      <td>ADH1A</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1      2     3\n",
       "0    ALDOA  226   FBP1  2203\n",
       "1    ALDOB  229   FBP1  2203\n",
       "2    ALDOC  230   FBP1  2203\n",
       "3    ALDH2  217  ADH1A   124\n",
       "4  ALDH1B1  219  ADH1A   124"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_network.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c012e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ESR1',\n",
       " 'ESR2',\n",
       " 'NCOA1',\n",
       " 'NCOA3',\n",
       " 'FOS',\n",
       " 'JUN',\n",
       " 'SP1',\n",
       " 'CCND1',\n",
       " 'MYC',\n",
       " 'PGR',\n",
       " 'WNT1',\n",
       " 'WNT4',\n",
       " 'TNFSF11',\n",
       " 'ERBB2',\n",
       " 'FGF1',\n",
       " 'FGF2',\n",
       " 'FGF3',\n",
       " 'FGF4',\n",
       " 'FGF17',\n",
       " 'FGF6',\n",
       " 'FGF7',\n",
       " 'FGF8',\n",
       " 'FGF9',\n",
       " 'FGF10',\n",
       " 'FGF16',\n",
       " 'FGF5',\n",
       " 'FGF18',\n",
       " 'FGF20',\n",
       " 'FGF22',\n",
       " 'FGF19',\n",
       " 'FGF21',\n",
       " 'FGF23',\n",
       " 'FGFR1',\n",
       " 'IGF1',\n",
       " 'IGF1R',\n",
       " 'EGF',\n",
       " 'EGFR',\n",
       " 'KIT',\n",
       " 'SHC1',\n",
       " 'SHC2',\n",
       " 'SHC3',\n",
       " 'SHC4',\n",
       " 'GRB2',\n",
       " 'SOS1',\n",
       " 'SOS2',\n",
       " 'HRAS',\n",
       " 'KRAS',\n",
       " 'NRAS',\n",
       " 'ARAF',\n",
       " 'BRAF',\n",
       " 'RAF1',\n",
       " 'MAP2K1',\n",
       " 'MAP2K2',\n",
       " 'MAPK1',\n",
       " 'MAPK3',\n",
       " 'PIK3CA',\n",
       " 'PIK3CD',\n",
       " 'PIK3CB',\n",
       " 'PIK3R1',\n",
       " 'PIK3R2',\n",
       " 'PIK3R3',\n",
       " 'PTEN',\n",
       " 'AKT1',\n",
       " 'AKT2',\n",
       " 'AKT3',\n",
       " 'MTOR',\n",
       " 'RPS6KB1',\n",
       " 'RPS6KB2',\n",
       " 'JAG1',\n",
       " 'JAG2',\n",
       " 'DLL3',\n",
       " 'DLL1',\n",
       " 'DLL4',\n",
       " 'NOTCH1',\n",
       " 'NOTCH2',\n",
       " 'NOTCH3',\n",
       " 'NOTCH4',\n",
       " 'HES1',\n",
       " 'HES5',\n",
       " 'HEYL',\n",
       " 'HEY1',\n",
       " 'HEY2',\n",
       " 'FLT4',\n",
       " 'CDKN1A',\n",
       " 'NFKB2',\n",
       " 'WNT2',\n",
       " 'WNT2B',\n",
       " 'WNT3',\n",
       " 'WNT3A',\n",
       " 'WNT5A',\n",
       " 'WNT5B',\n",
       " 'WNT6',\n",
       " 'WNT7A',\n",
       " 'WNT7B',\n",
       " 'WNT8A',\n",
       " 'WNT8B',\n",
       " 'WNT9A',\n",
       " 'WNT9B',\n",
       " 'WNT10B',\n",
       " 'WNT10A',\n",
       " 'WNT11',\n",
       " 'WNT16',\n",
       " 'FZD1',\n",
       " 'FZD7',\n",
       " 'FZD2',\n",
       " 'FZD3',\n",
       " 'FZD4',\n",
       " 'FZD5',\n",
       " 'FZD8',\n",
       " 'FZD6',\n",
       " 'FZD10',\n",
       " 'FZD9',\n",
       " 'LRP5',\n",
       " 'LRP6',\n",
       " 'DVL3',\n",
       " 'DVL2',\n",
       " 'DVL1',\n",
       " 'FRAT1',\n",
       " 'FRAT2',\n",
       " 'GSK3B',\n",
       " 'AXIN1',\n",
       " 'AXIN2',\n",
       " 'APC',\n",
       " 'APC2',\n",
       " 'CTNNB1',\n",
       " 'CSNK1A1L',\n",
       " 'CSNK1A1',\n",
       " 'TCF7',\n",
       " 'TCF7L1',\n",
       " 'TCF7L2',\n",
       " 'LEF1',\n",
       " 'TP53',\n",
       " 'GADD45A',\n",
       " 'GADD45B',\n",
       " 'GADD45G',\n",
       " 'BAX',\n",
       " 'BAK1',\n",
       " 'DDB2',\n",
       " 'POLK',\n",
       " 'CDK4',\n",
       " 'CDK6',\n",
       " 'RB1',\n",
       " 'E2F1',\n",
       " 'E2F2',\n",
       " 'E2F3',\n",
       " 'BRCA1',\n",
       " 'BRCA2']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEGG['hsa05224']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2a282bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sc5rJUQ039_AAACGGGAGTGGACGT</th>\n",
       "      <th>sc5rJUQ039_AAAGCAACAATGGACG</th>\n",
       "      <th>sc5rJUQ039_AAATGCCAGTAAGTAC</th>\n",
       "      <th>sc5rJUQ039_AAGTCTGCATCACAAC</th>\n",
       "      <th>sc5rJUQ039_ACATCAGAGTAGCGGT</th>\n",
       "      <th>sc5rJUQ039_ACGGGCTAGACTCGGA</th>\n",
       "      <th>sc5rJUQ039_ACTGCTCCACTATCTT</th>\n",
       "      <th>sc5rJUQ039_ACTGCTCGTATATGGA</th>\n",
       "      <th>sc5rJUQ039_ACTTTCAAGTGAATTG</th>\n",
       "      <th>...</th>\n",
       "      <th>sc5rJUQ039_TGAGGGAAGAGATGAG</th>\n",
       "      <th>sc5rJUQ039_TGCGGGTCAGCAGTTT</th>\n",
       "      <th>sc5rJUQ039_TGGCGCACAAGCCTAT</th>\n",
       "      <th>sc5rJUQ039_TGGGCGTTCACAGGCC</th>\n",
       "      <th>sc5rJUQ039_TGGTTAGTCACGCGGT</th>\n",
       "      <th>sc5rJUQ039_TGGTTCCTCCAGATCA</th>\n",
       "      <th>sc5rJUQ039_TGTGGTATCAAAGTAG</th>\n",
       "      <th>sc5rJUQ039_TTCCCAGAGTGAACAT</th>\n",
       "      <th>sc5rJUQ039_TTGGCAACACTGAAGG</th>\n",
       "      <th>sc5rJUQ039_TTTACTGAGTGCCAGA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FO538757.2</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.491</td>\n",
       "      <td>1.017</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOC2L</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.724</td>\n",
       "      <td>1.015</td>\n",
       "      <td>0.862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.638</td>\n",
       "      <td>1.069</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISG15</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SDF4</td>\n",
       "      <td>1.903</td>\n",
       "      <td>1.792</td>\n",
       "      <td>1.627</td>\n",
       "      <td>1.749</td>\n",
       "      <td>1.691</td>\n",
       "      <td>1.766</td>\n",
       "      <td>1.905</td>\n",
       "      <td>1.668</td>\n",
       "      <td>1.691</td>\n",
       "      <td>...</td>\n",
       "      <td>1.796</td>\n",
       "      <td>1.523</td>\n",
       "      <td>1.699</td>\n",
       "      <td>1.696</td>\n",
       "      <td>1.669</td>\n",
       "      <td>1.849</td>\n",
       "      <td>1.645</td>\n",
       "      <td>1.706</td>\n",
       "      <td>1.505</td>\n",
       "      <td>1.704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UBE2J2</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  sc5rJUQ039_AAACGGGAGTGGACGT  sc5rJUQ039_AAAGCAACAATGGACG  \\\n",
       "0  FO538757.2                        0.778                        0.508   \n",
       "1       NOC2L                        0.762                        0.697   \n",
       "2       ISG15                        0.457                        0.231   \n",
       "3        SDF4                        1.903                        1.792   \n",
       "4      UBE2J2                        0.575                        0.512   \n",
       "\n",
       "   sc5rJUQ039_AAATGCCAGTAAGTAC  sc5rJUQ039_AAGTCTGCATCACAAC  \\\n",
       "0                        0.451                        0.478   \n",
       "1                        0.962                        0.838   \n",
       "2                        0.187                        0.207   \n",
       "3                        1.627                        1.749   \n",
       "4                        0.822                        0.613   \n",
       "\n",
       "   sc5rJUQ039_ACATCAGAGTAGCGGT  sc5rJUQ039_ACGGGCTAGACTCGGA  \\\n",
       "0                        0.974                        0.490   \n",
       "1                        0.778                        0.674   \n",
       "2                        0.181                        0.216   \n",
       "3                        1.691                        1.766   \n",
       "4                        0.698                        0.501   \n",
       "\n",
       "   sc5rJUQ039_ACTGCTCCACTATCTT  sc5rJUQ039_ACTGCTCGTATATGGA  \\\n",
       "0                        0.529                        0.669   \n",
       "1                        0.724                        1.015   \n",
       "2                        0.652                        0.541   \n",
       "3                        1.905                        1.668   \n",
       "4                        0.525                        0.493   \n",
       "\n",
       "   sc5rJUQ039_ACTTTCAAGTGAATTG  ...  sc5rJUQ039_TGAGGGAAGAGATGAG  \\\n",
       "0                        0.493  ...                        0.715   \n",
       "1                        0.862  ...                        0.890   \n",
       "2                        0.573  ...                        0.233   \n",
       "3                        1.691  ...                        1.796   \n",
       "4                        0.503  ...                        0.513   \n",
       "\n",
       "   sc5rJUQ039_TGCGGGTCAGCAGTTT  sc5rJUQ039_TGGCGCACAAGCCTAT  \\\n",
       "0                        0.606                        0.404   \n",
       "1                        0.926                        0.868   \n",
       "2                        0.175                        0.410   \n",
       "3                        1.523                        1.699   \n",
       "4                        0.575                        0.550   \n",
       "\n",
       "   sc5rJUQ039_TGGGCGTTCACAGGCC  sc5rJUQ039_TGGTTAGTCACGCGGT  \\\n",
       "0                        0.624                        0.478   \n",
       "1                        0.616                        0.659   \n",
       "2                        0.183                        0.207   \n",
       "3                        1.696                        1.669   \n",
       "4                        0.471                        0.493   \n",
       "\n",
       "   sc5rJUQ039_TGGTTCCTCCAGATCA  sc5rJUQ039_TGTGGTATCAAAGTAG  \\\n",
       "0                        0.491                        1.017   \n",
       "1                        0.676                        0.638   \n",
       "2                        0.217                        0.195   \n",
       "3                        1.849                        1.645   \n",
       "4                        0.746                        0.483   \n",
       "\n",
       "   sc5rJUQ039_TTCCCAGAGTGAACAT  sc5rJUQ039_TTGGCAACACTGAAGG  \\\n",
       "0                        0.505                        0.620   \n",
       "1                        1.069                        0.614   \n",
       "2                        0.228                        0.123   \n",
       "3                        1.706                        1.505   \n",
       "4                        0.510                        0.590   \n",
       "\n",
       "   sc5rJUQ039_TTTACTGAGTGCCAGA  \n",
       "0                        0.503  \n",
       "1                        0.691  \n",
       "2                        0.227  \n",
       "3                        1.704  \n",
       "4                        0.509  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BRCA_exp_filter_saver = pd.read_csv('Cancer_Datasets/S39_Cancer_BRCA_output.csv')\n",
    "BRCA_exp_filter_saver.head()\n",
    "# BRCA_exp_filter_saver的形状:(基因个数,细胞个数)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d5f0ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_symmetric(matrix):\n",
    "    # 检查是否为二维数组且行列数相等（方阵）\n",
    "    if matrix.ndim != 2 or matrix.shape[0] != matrix.shape[1]:\n",
    "        return False\n",
    "    # 使用allclose处理浮点数精度问题\n",
    "    return np.allclose(matrix, matrix.T)\n",
    "\n",
    "a = np.array([[1,2],[2,1]])\n",
    "is_symmetric(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b9d3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "边的数量 169 166 1.0180722891566265\n",
      "cmi是对的\n",
      "False\n",
      "{'Pathway': 'hsa05224', 'NUM_ORIG': 67.46987951807229, 'NUM_PCC': 18.92661555312158, 'NUM_MI': 13.603504928806133}\n",
      "Cancer_Datasets/S33_T_cell_BRCA_output_meta.data is OK!!!!\n",
      "边的数量 187 199 0.9396984924623115\n",
      "cmi是对的\n",
      "False\n",
      "{'Pathway': 'hsa05224', 'NUM_ORIG': 85.42713567839196, 'NUM_PCC': 14.070351758793967, 'NUM_MI': 0.5025125628140702}\n",
      "Cancer_Datasets/S39_T_cell_BRCA_output_meta.data is OK!!!!\n",
      "边的数量 153 174 0.8793103448275862\n",
      "cmi是对的\n",
      "False\n",
      "{'Pathway': 'hsa05224', 'NUM_ORIG': 80.45977011494253, 'NUM_PCC': 19.54022988505747, 'NUM_MI': 0}\n",
      "Cancer_Datasets/S42_T_cell_BRCA_output_meta.data is OK!!!!\n",
      "边的数量 283 309 0.9158576051779935\n",
      "cmi是对的\n",
      "False\n",
      "{'Pathway': 'hsa05224', 'NUM_ORIG': 77.02265372168284, 'NUM_PCC': 11.974110032362459, 'NUM_MI': 11.003236245954692}\n",
      "Cancer_Datasets/S53_T_cell_BRCA_output_meta.data is OK!!!!\n",
      "边的数量 239 265 0.9018867924528302\n",
      "cmi是对的\n",
      "False\n",
      "{'Pathway': 'hsa05224', 'NUM_ORIG': 77.35849056603774, 'NUM_PCC': 19.622641509433954, 'NUM_MI': 3.0188679245283003}\n",
      "Cancer_Datasets/S60_T_cell_BRCA_output_meta.data is OK!!!!\n",
      "边的数量 198 203 0.9753694581280788\n",
      "cmi是对的\n",
      "False\n",
      "{'Pathway': 'hsa05224', 'NUM_ORIG': 76.35467980295566, 'NUM_PCC': 20.689655172413794, 'NUM_MI': 2.955665024630542}\n",
      "Cancer_Datasets/S33_B_cell_BRCA_output_meta.data is OK!!!!\n",
      "边的数量 197 204 0.9656862745098039\n",
      "cmi是对的\n",
      "False\n",
      "{'Pathway': 'hsa05224', 'NUM_ORIG': 79.41176470588235, 'NUM_PCC': 18.716577540106954, 'NUM_MI': 1.8716577540106956}\n",
      "Cancer_Datasets/S39_B_cell_BRCA_output_meta.data is OK!!!!\n",
      "边的数量 178 175 1.0171428571428571\n",
      "cmi是对的\n",
      "False\n",
      "{'Pathway': 'hsa05224', 'NUM_ORIG': 79.42857142857143, 'NUM_PCC': 20.0, 'NUM_MI': 0.5714285714285714}\n",
      "Cancer_Datasets/S42_B_cell_BRCA_output_meta.data is OK!!!!\n",
      "边的数量 369 392 0.9413265306122449\n",
      "cmi是对的\n",
      "False\n",
      "{'Pathway': 'hsa05224', 'NUM_ORIG': 82.6530612244898, 'NUM_PCC': 14.030612244897958, 'NUM_MI': 3.316326530612245}\n",
      "Cancer_Datasets/S53_B_cell_BRCA_output_meta.data is OK!!!!\n",
      "边的数量 305 321 0.9501557632398754\n",
      "cmi是对的\n",
      "False\n",
      "{'Pathway': 'hsa05224', 'NUM_ORIG': 73.83177570093457, 'NUM_PCC': 17.445482866043612, 'NUM_MI': 8.722741433021806}\n",
      "Cancer_Datasets/S60_B_cell_BRCA_output_meta.data is OK!!!!\n",
      "边的数量 466 520 0.8961538461538462\n",
      "cmi是对的\n",
      "False\n",
      "{'Pathway': 'hsa05224', 'NUM_ORIG': 74.42307692307692, 'NUM_PCC': 17.5, 'NUM_MI': 8.076923076923077}\n",
      "Cancer_Datasets/S33_Cancer_BRCA_output_meta.data is OK!!!!\n",
      "边的数量 428 499 0.8577154308617234\n",
      "cmi是对的\n",
      "False\n",
      "{'Pathway': 'hsa05224', 'NUM_ORIG': 81.56312625250501, 'NUM_PCC': 8.817635270541082, 'NUM_MI': 9.619238476953909}\n",
      "Cancer_Datasets/S42_Cancer_BRCA_output_meta.data is OK!!!!\n",
      "边的数量 277 306 0.9052287581699346\n",
      "cmi是对的\n",
      "False\n",
      "{'Pathway': 'hsa05224', 'NUM_ORIG': 70.91503267973856, 'NUM_PCC': 17.647058823529413, 'NUM_MI': 11.437908496732026}\n",
      "Cancer_Datasets/S53_Cancer_BRCA_output_meta.data is OK!!!!\n",
      "边的数量 388 460 0.8434782608695652\n",
      "cmi是对的\n",
      "False\n",
      "{'Pathway': 'hsa05224', 'NUM_ORIG': 85.0, 'NUM_PCC': 13.695652173913043, 'NUM_MI': 1.3043478260869565}\n",
      "Cancer_Datasets/S60_Cancer_BRCA_output_meta.data is OK!!!!\n"
     ]
    }
   ],
   "source": [
    "for si in celllist:\n",
    "        for ji in filelist:\n",
    "            # 39_Cancer作为测试集\n",
    "            if not((str(ji) == '39') and (si == \"Cancer\")):\n",
    "                #原代码路径有误,已根据实际情况修改\n",
    "                filepath = 'Cancer_Datasets/S'+str(ji)+'_' + si+'_BRCA_output.csv'\n",
    "                BRCA_exp_filter_saver = pd.read_csv(filepath)\n",
    "                #原代码在删除第一列的操作有误,多删除了一列,已修改\n",
    "                BRCA_exp_filter_saver.set_index(BRCA_exp_filter_saver.iloc[:,0],inplace=True)\n",
    "                BRCA_exp_filter_saver.drop(columns = BRCA_exp_filter_saver.columns[0],inplace = True)\n",
    "                BRCA_exp_filter_saver_metacell = cal_metacell(BRCA_exp_filter_saver, Cnum=Cnum, k=k)# (基因个数,metacell个数)\n",
    "                filepath = filepath.replace('output','output_meta')\n",
    "                if BRCA_exp_filter_saver is not None:\n",
    "                    parm = {'pear_percent': 4, 'MI_percent': 4, 'pmi_percent': 0.001}\n",
    "                    [exp, adj_matrix, new_row] = from_cancer_create(BRCA_exp_filter_saver_metacell,\n",
    "                                                                    KEGG,\n",
    "                                                                    parm,\n",
    "                                                                    test_pathway=None,\n",
    "                                                                    Other_Pathway=test_pathway,\n",
    "                                                                    human_network=human_network)\n",
    "                    \"\"\" data1 = np.sum(adj_matrix, axis=0)\n",
    "                    fit1 = powerlaw.Fit(data1)\n",
    "                    data2 = np.sum(adj_matrix, axis=1)\n",
    "                    fit2 = powerlaw.Fit(data2)\n",
    "                    data3 = data1+data2\n",
    "                    fit3 = powerlaw.Fit(data3)\n",
    "                    print(\"Alpha (exponent,0):\", fit1.alpha, \"Alpha (exponent,1):\", fit2.alpha, \"Alpha (exponent,sum):\", fit3.alpha) \"\"\"\n",
    "                    #源代码中以上这段拟合意义不明,没有在其他地方出现,而且数据不符合幂律分布拟合的要求(全部大于0),所以注释掉\n",
    "                    data = {\"net\": adj_matrix, \"exp\": np.array(exp), \"genename\": exp.index}\n",
    "                    print(is_symmetric(adj_matrix))\n",
    "                    print(new_row)\n",
    "                    filename = filepath.replace(\"csv\", \"data\")\n",
    "                    f = open(filename, 'wb')\n",
    "                    pickle.dump(data, f)\n",
    "                    f.close()\n",
    "\n",
    "                    sio.savemat(filepath.replace(\"csv\", \"mat\"), {\"net\": adj_matrix, \"exp\": np.array(exp), \"genename\": exp.index})\n",
    "                    print(filename+' is OK!!!!')\n",
    "\n",
    "# 输出解释:\n",
    "# 第一行:pearson-mi,cmi边的数量与比值\n",
    "# 第二行:预处理选择了pearson-mi/cmi中的一个图\n",
    "# 第三行:邻接矩阵是否对称\n",
    "# 第四行:图的统计信息\n",
    "# 第五行:文件夹处理完毕的输出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ca3662",
   "metadata": {},
   "source": [
    "## 4.其他文件\n",
    "`pathway/PCA_CMI.py`\n",
    ">conditional_mutual_info(X, Y, Z=np.array(1)):\n",
    "计算条件互信息cmi,多元正态分布\n",
    "如果X,Y是1维,修改形状为(-1,1)的2维数组.此处应该有误,因为cov是将每行当作特征,每列当作样本,(-1,1)的形状算不出协方差,(1,-1)的形状才能算出单个向量的方差.这里没出现报错,输入X,Y应该都是2维数组,列数相同(才能进行cov计算)\n",
    "Z是常数或向量,用矩阵来说是0维或1维\n",
    "分以下两种情况:\n",
    "1.Z是0维,即Z不是一个条件,cmi退化成mi\n",
    "d1,d2分别是X,Y的协方差的行列式\n",
    "d3是X和Y拼接后的协方差的行列式\n",
    "cmi = (1 / 2) * np.log((d1 * d2) / d3)\n",
    "2.Z是1维,即Z是条件\n",
    "d1是X,Z的协方差的行列式\n",
    "d2是Y,Z的协方差的行列式\n",
    "d3是Z的协方差的行列式\n",
    "d4是X,Y,Z的协方差的行列式\n",
    "cmi = (1 / 2) * np.log((d1 * d2) / (d3 * d4))\n",
    "关于公式推导见**补充知识**\n",
    "return cmi\n",
    "\n",
    ">remove_edges(predicted_graph, data, L, theta):\n",
    "先从predicted_graph中获得边的数量initial_num_edges和所有边edges\n",
    "遍历每条边edge:\n",
    "neighbors1 = edge[0]的子节点集合\n",
    "neighbors2 = edge[1]的子节点集合\n",
    "neighbors = 以上两个集合取交集,即两个点的公共子节点集合\n",
    "nhbrs = neighbors的拷贝\n",
    "T = 公共子节点个数\n",
    "如果T < L(阈值)或者edge的两个点相同(即edge是自环边),不进行操作\n",
    "否则:\n",
    "在data中根据edge的两个端点找到x,y,他们的形状是(-1,1)\n",
    "K = 在nhbrs中选择L个的组合\n",
    "1.如果L == 0:\n",
    "cmiVal = conditionconditional_mutual_info(x.T, y.T)\n",
    "这个转置(即(1,-1)的输入)也跳过了上面conditionconditional_mutual_info中不合理的判别\n",
    "如果cmiVal < theta则删除这条边\n",
    "2.否则:遍历K中的zgroup\n",
    "2.1 zgroup中没有数据,则跳过\n",
    "2.2 data中通过zgroup查找z,即影响xy互信息的条件\n",
    "cmiVal = conditional_mutual_info(x.T, y.T, z.T)\n",
    "在对zgroup的遍历中获得最大的cmi,如果小于theta则删除这条边\n",
    "在对每条边进行判断是否删除的操作后,计算图中边的数量,如果比输入时减少了,return predicted_graph, False\n",
    "否则return predicted_graph, True\n",
    "\n",
    ">pca_cmi(data, new_net_bit, theta, max_order, show=False):\n",
    "创建有向图predicted_graph,节点为data的index\n",
    "new_net_bit中的两列TF,Gene分别是每条边的头节点,尾节点\n",
    "L = 0\n",
    "nochange = False\n",
    "data = data.T\n",
    "循环,不断增加L,直到nochange == True\n",
    "这个循环隐含的假设是,随着L增大,条件越多,cmi值会越小,导致不断有边被删除,直到所有边的端点的cmi大于theta,不能被删除.\n",
    "但是查找资料:条件越多,条件互信息不一定越小或越大,其变化取决于条件变量与目标变量之间的因果或依赖结构.也就是说cmi不是一个单调的结构,这一段也需要考察.\n",
    "调用时L = 1,即删除操作只进行一次,也不用考察L更大时的单调性质了.\n",
    "show参数默认是False,如果为True有一段打印信息,调试时可以使用.\n",
    "返回邻接矩阵和图结构\n",
    "return predicted_adjMatrix, predicted_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aedbd1",
   "metadata": {},
   "source": [
    "## 5.补充知识\n",
    "### 5.1 互信息(mi)和条件互信息(cmi)\n",
    "熵,联合熵,条件熵的定义\n",
    "$H(x) = -\\sum_x p(x)log(p(x))\\\\\n",
    "H(x,y) = -\\sum_{x}\\sum_{y} p(x,y)log(p(x,y))\\\\\n",
    "H(x|y) = H(x,y) - H(y)$ \n",
    "首先,证明互信息mi的熵表达式和概率表达式等价\n",
    "`熵表达式`\n",
    "$mi(x,y) = H(x) + H(y) - H(x,y)\\\\\n",
    "=H(x)-H(x|y)= H(y) - H(y|x)$\n",
    "`概率表达式`\n",
    "$mi(x,y) = \\sum_{x}\\sum_{y} p(x,y)log(\\frac{p(x,y)}{p(x)p(y)})$\n",
    "证明:\n",
    "$$\\begin{align*}\n",
    "mi(x,y) &= H(x) + H(y) - H(x,y) \\\\\n",
    "&= -\\sum_x p(x)log(p(x))-\\sum_y p(y)log(p(y))+\\sum_{x}\\sum_{y} p(x,y)log(p(x,y)) \\\\\n",
    "&= -\\sum_x\\sum_{y} p(x,y)log(p(x))-\\sum_{x}\\sum_y p(x,y)log(p(y))+\\sum_{x}\\sum_{y} p(x,y)log(p(x,y)) \\\\\n",
    "&=\\sum_{x}\\sum_{y} p(x,y)log(\\frac{p(x,y)}{p(x)p(y)})\n",
    "\\end{align*}$$\n",
    "\n",
    "条件互信息cmi\n",
    "$cmi(x,y|z) =  H(x|z) + H(y|z) - H(x,y|z)\\\\ = \\sum_zp(z)mi(x,y|z)$\n",
    "\n",
    "关于本文中计算cmi的方法,网上的解释:\n",
    "条件互信息（CMI）与行列式之间存在一定的联系，但直接使用行列式计算CMI并不常见，需要根据具体情况分析。下面从理论和实际应用两个角度进行说明：\n",
    "\n",
    "\n",
    "#### **1. 理论上的联系**\n",
    "对于**多元高斯分布**，CMI可以通过协方差矩阵的行列式计算。假设随机变量 \\( X, Y, Z \\) 服从联合高斯分布，则：\n",
    "\\[\n",
    "\\text{CMI}(X;Y|Z) = \\frac{1}{2} \\ln \\left( \\frac{\\det(\\Sigma_{XZ}) \\cdot \\det(\\Sigma_{YZ})}{\\det(\\Sigma_{Z}) \\cdot \\det(\\Sigma_{XYZ})} \\right)\n",
    "\\]\n",
    "其中：\n",
    "- \\( \\Sigma_{XZ} \\) 是 \\( X \\) 和 \\( Z \\) 的协方差矩阵\n",
    "- \\( \\Sigma_{YZ} \\) 是 \\( Y \\) 和 \\( Z \\) 的协方差矩阵\n",
    "- \\( \\Sigma_{Z} \\) 是 \\( Z \\) 的协方差矩阵\n",
    "- \\( \\Sigma_{XYZ} \\) 是 \\( X, Y, Z \\) 的联合协方差矩阵\n",
    "\n",
    "**推导思路**：\n",
    "高斯分布的微分熵为 \\( H(X) = \\frac{1}{2} \\ln \\left( (2\\pi e)^n \\det(\\Sigma_X) \\right) \\)，代入CMI的熵表达式：\n",
    "\\[\n",
    "\\text{CMI}(X;Y|Z) = H(X|Z) + H(Y|Z) - H(X,Y|Z)\n",
    "\\]\n",
    "通过行列式的比值化简可得上述公式。\n",
    "\n",
    "\n",
    "#### **2. 离散数据的CMI与行列式**\n",
    "对于**离散数据**，CMI的定义基于概率分布，而非协方差矩阵，因此**无法直接使用行列式计算**。例如：\n",
    "\\[\n",
    "\\text{CMI}(X;Y|Z) = \\sum_{x,y,z} P(x,y,z) \\log \\frac{P(x,y|z)}{P(x|z) \\cdot P(y|z)}\n",
    "\\]\n",
    "此时需要通过统计频率估计概率分布，而非行列式。\n",
    "\n",
    "#### 总结\n",
    "本文假设变量都服从多元高斯分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c13551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.7388948450374015, 0.04718490304900292)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#计算互信息的代码,可以看出用两种方法得到的mi差别很大\n",
    "#注,mutual_info_score仅适用于离散数据,基于行列式的计算方法仅适用于多元高斯分布,\n",
    "#所以两种方法可比性不高,但是本文中两种方式都出现了,需要考察\n",
    "from sklearn.metrics import mutual_info_score\n",
    "x = np.random.randn(20)\n",
    "y = np.random.randn(20)\n",
    "#离散化\n",
    "bins = np.linspace(min(x),max(x),21)\n",
    "bins1 = np.linspace(min(y),max(y),21)\n",
    "labels = list(range(20))\n",
    "x_discrete = pd.cut(x,bins = bins,labels = labels,include_lowest=True)\n",
    "y_discrete = pd.cut(y,bins = bins1,labels = labels,include_lowest=True)\n",
    "mi1 = mutual_info_score(x_discrete.to_list(),y_discrete.to_list())\n",
    "d1 = np.cov(x_discrete)\n",
    "d2 = np.cov(y_discrete)\n",
    "d3 = np.linalg.det(np.cov(x_discrete,y_discrete))\n",
    "mi2 = 1/2 * np.log((d1 * d2)/d3)\n",
    "mi1, mi2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91c326b",
   "metadata": {},
   "source": [
    "### 5.2 初始化与激活函数\n",
    "discrete/models/train_metrics.py中,使用了两种初始化方法,kaiming初始化和xavier初始化.\n",
    "两种方法的比较如下\n",
    "#### 1. **Xavier 初始化**（Glorot 初始化）&#xA;\n",
    "\n",
    "*   **适用激活函数**：Sigmoid、Tanh、Softmax 等近似线性激活函数。\n",
    "\n",
    "*   **数学原理**：权重 $W$ 的方差满足：\n",
    "\n",
    "$\\text{Var}(W) = \\frac{2}{\\text{fan\\_in} + \\text{fan\\_out}}$\n",
    "\n",
    "其中 $\\text{fan\\_in}$ 和 $\\text{fan\\_out}$ 分别为输入和输出神经元数量。\n",
    "\n",
    "#### 2. **Kaiming 初始化**（He 初始化）&#xA;\n",
    "\n",
    "\n",
    "\n",
    "*   **适用激活函数**：ReLU、LeakyReLU、PReLU 等 ReLU 类激活函数。\n",
    "\n",
    "\n",
    "*   **数学原理**：考虑到 ReLU 对负值区域的抑制，权重 $W$ 的方差调整为：\n",
    "\n",
    "\n",
    "$\\text{Var}(W) = \\frac{2}{\\text{fan\\_in}}$\n",
    "\n",
    "其中 $\\text{fan\\_in}$ 为输入神经元数量。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1818c5e8",
   "metadata": {},
   "source": [
    "## 其他内容\n",
    ".gitignore配置文件增加*.data,*.mat,*.csv,忽略解压出来的大文件"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dignet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
